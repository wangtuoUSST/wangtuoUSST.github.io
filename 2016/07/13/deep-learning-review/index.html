<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>神经网络中的深度学习：综述| Deep Learning in Neural Networks: An Overview | 机器学习及自然语言处理</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="关于Deep Learning in Neural Networks: An Overview的粗糙翻译和个人理解
摘要：近年来，深度人工神经网络赢得了大量模式识别与机器学习方面的比赛。这篇历史考察简要地总结了神经网络的相关工作，其中很多内容来自2000年之前。学习的深浅依据其CAP的深度来区分，即行为与影响之间的可学习链和因果联系的深度
停一下
什么是CAP(credit assignment">
<meta property="og:type" content="article">
<meta property="og:title" content="神经网络中的深度学习：综述| Deep Learning in Neural Networks: An Overview">
<meta property="og:url" content="http://yoursite.com/2016/07/13/deep-learning-review/index.html">
<meta property="og:site_name" content="机器学习及自然语言处理">
<meta property="og:description" content="关于Deep Learning in Neural Networks: An Overview的粗糙翻译和个人理解
摘要：近年来，深度人工神经网络赢得了大量模式识别与机器学习方面的比赛。这篇历史考察简要地总结了神经网络的相关工作，其中很多内容来自2000年之前。学习的深浅依据其CAP的深度来区分，即行为与影响之间的可学习链和因果联系的深度
停一下
什么是CAP(credit assignment">
<meta property="og:updated_time" content="2016-07-13T08:26:44.849Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="神经网络中的深度学习：综述| Deep Learning in Neural Networks: An Overview">
<meta name="twitter:description" content="关于Deep Learning in Neural Networks: An Overview的粗糙翻译和个人理解
摘要：近年来，深度人工神经网络赢得了大量模式识别与机器学习方面的比赛。这篇历史考察简要地总结了神经网络的相关工作，其中很多内容来自2000年之前。学习的深浅依据其CAP的深度来区分，即行为与影响之间的可学习链和因果联系的深度
停一下
什么是CAP(credit assignment">
  
    <link rel="alternate" href="/atom.xml" title="机器学习及自然语言处理" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">机器学习及自然语言处理</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">随手笔记</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-deep-learning-review" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/07/13/deep-learning-review/" class="article-date">
  <time datetime="2016-07-13T08:25:29.000Z" itemprop="datePublished">2016-07-13</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/deep-learning/">deep learning</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      神经网络中的深度学习：综述| Deep Learning in Neural Networks: An Overview
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>关于<a href="http://arxiv.org/pdf/1404.7828.pdf" target="_blank" rel="external">Deep Learning in Neural Networks: An Overview</a>的粗糙翻译和个人理解</p>
<h3 id="摘要："><a href="#摘要：" class="headerlink" title="摘要："></a><strong>摘要：</strong></h3><p>近年来，深度人工神经网络赢得了大量模式识别与机器学习方面的比赛。这篇历史考察简要地总结了神经网络的相关工作，其中很多内容来自2000年之前。学习的深浅依据其CAP的深度来区分，即行为与影响之间的可学习链和因果联系的深度</p>
<h4 id="停一下"><a href="#停一下" class="headerlink" title="停一下"></a><strong>停一下</strong></h4><ul>
<li>什么是CAP(credit assignment paths)<br><a href="https://en.wikipedia.org/wiki/Deep_learning" target="_blank" rel="external">CAP</a>: Credit Assignment Path (字面上翻译成信用分配路径，wiki: A chain of transformations from input to output is a credit assignment path (CAP). CAPs describe potentially causal connections between input and output and may vary in length. For a feedforward neural network, the depth of the CAPs, and thus the depth of the network, is the number of hidden layers plus one (the output layer is also parameterized). For recurrent neural networks, in which a signal may propagate through a layer more than once, the CAP is potentially unlimited in length. There is no universally agreed upon threshold of depth dividing shallow learning from deep learning, but most researchers in the field agree that deep learning has multiple nonlinear layers (CAP &gt; 2) and Schmidhuber considers CAP &gt; 10 to be very deep learning)<br>CAP即输入到输出间的转换链(比如神经网络的神经元之间的输入输出转换？),CAPs描述了输入输出间可能的因果关系，并且长度有可能发生变化。对于一个前向反馈神经网络，其CAPs的深度，也即这一网络深度是其隐层数加一。对于递归神经网络，由于信号可能多次经过某个隐层，其CAPs有可能无限长。对于区分浅学习和深度学习的CAPs深度界限是多大并没有一个被普遍接受的结论，但这一领域的绝大多数研究者同意深度学习具有多元非线性的隐层（？？？），并且Schmidhuber认为CAP大于10就已经是非常深的深度学习了。</li>
</ul>
<h4 id="接着说"><a href="#接着说" class="headerlink" title="接着说"></a><strong>接着说</strong></h4><p>作者回顾了深度监督学习（包括反向传播的历史），无监督学习，强化学习和进化算法，以及and indirect search for short programs encoding deep and large networks.(这里不太理解，留待后续补充)</p>
<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a><strong>前言</strong></h3><p>（写作目的之类的介绍，暂且略过）</p>
<h2 id="对神经网络-NNs-中的深度学习-DL-的介绍"><a href="#对神经网络-NNs-中的深度学习-DL-的介绍" class="headerlink" title="对神经网络(NNs)中的深度学习(DL)的介绍"></a><strong>对神经网络(NNs)中的深度学习(DL)的介绍</strong></h2><p>对于一个学习系统而言，决定其成功与否的可调节要素是什么？对它的何种调整可以提升其性能？这两个问题被称之为fundamental credit assignment problem. There are general credit assignment methods for universal problem solvers that are time-optimal in various theoretical senses (Sec. 6.8).然而目前的研究主要关注更窄但更有商业价值的领域：人工神经网络中的深度学习子领域。<br>一个标准的NN包含许多简单的相互连接的神经元，分别产生一系列的激活值。输入神经元由传感器对环境的感知而激活，其他的神经元通过带权重的连接被前一个神经元激活。某些神经元可以通过触发行为影响环境。Learning or credit assignment是寻找恰当的权重使NN表现出期望的行为，如驾驶汽车。对于不同的问题和神经元的连接方式，这种行为可能需要很长的causal chains of computational stages。DL通过很长的这种阶来精确求解。<br>20世纪80年代发现BP算法对隐层较多的神经网络而言是难以实现的，在1991年，通过无监督学习的帮助，DL在一定范围内是可以实现的。从2009年起，有监督DNN在很多官方模式识别比赛中获得惊人成绩，取得广泛关注。DNN也在其他更广泛的领域中发挥了重要作用。</p>
<h2 id="Event-Oriented-Notation-for-Activation-Spreading-in-NNs"><a href="#Event-Oriented-Notation-for-Activation-Spreading-in-NNs" class="headerlink" title="Event-Oriented Notation for Activation Spreading in NNs"></a><strong>Event-Oriented Notation for Activation Spreading in NNs</strong></h2><p>在这篇论文中，i, j, k, t, p, q, r表示假定的取值范围已经在上下文中给出的正整数变量，n, m, T表示未给出的正整数变量。<br>一个神经网络的拓扑结构可能随时间而改变。在给定的时刻，其结构可以描述为一个有限的单元(节点或者神经元)集合 N={u_1,u_2,…,}和一个节点间有向边构成的集合H。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2016/07/13/deep-learning-review/" data-id="ciqkmijt90000igo00mn99tuw" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2016/07/12/hello-world/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Hello World</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/deep-learning/">deep learning</a></li></ul>
    </div>
  </div>


  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/07/13/deep-learning-review/">神经网络中的深度学习：综述| Deep Learning in Neural Networks: An Overview</a>
          </li>
        
          <li>
            <a href="/2016/07/12/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 王椭<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>